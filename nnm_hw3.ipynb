{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnm_hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# дз 3 по нейросетям"
      ],
      "metadata": {
        "id": "ipWK13H1DpFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0tS5nXV-TfiS"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сейчас достанем нужные даные"
      ],
      "metadata": {
        "id": "tKHDShggo7Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Fake.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "j39PLtvsTjfq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "4zAoampnlvli",
        "outputId": "1e4cc6db-c4aa-43c5-ac65-73d8bea623d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88f71244-8228-4c7a-88d3-a5fb0f974219\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23476</th>\n",
              "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
              "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>January 16, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23477</th>\n",
              "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
              "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>January 16, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23478</th>\n",
              "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
              "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>January 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23479</th>\n",
              "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
              "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>January 14, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23480</th>\n",
              "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
              "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
              "      <td>Middle-east</td>\n",
              "      <td>January 12, 2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23481 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88f71244-8228-4c7a-88d3-a5fb0f974219')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88f71244-8228-4c7a-88d3-a5fb0f974219 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88f71244-8228-4c7a-88d3-a5fb0f974219');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   title  ...               date\n",
              "0       Donald Trump Sends Out Embarrassing New Year’...  ...  December 31, 2017\n",
              "1       Drunk Bragging Trump Staffer Started Russian ...  ...  December 31, 2017\n",
              "2       Sheriff David Clarke Becomes An Internet Joke...  ...  December 30, 2017\n",
              "3       Trump Is So Obsessed He Even Has Obama’s Name...  ...  December 29, 2017\n",
              "4       Pope Francis Just Called Out Donald Trump Dur...  ...  December 25, 2017\n",
              "...                                                  ...  ...                ...\n",
              "23476  McPain: John McCain Furious That Iran Treated ...  ...   January 16, 2016\n",
              "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...  ...   January 16, 2016\n",
              "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...  ...   January 15, 2016\n",
              "23479  How to Blow $700 Million: Al Jazeera America F...  ...   January 14, 2016\n",
              "23480  10 U.S. Navy Sailors Held by Iranian Military ...  ...   January 12, 2016\n",
              "\n",
              "[23481 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на все и сделаем предобработку"
      ],
      "metadata": {
        "id": "WQex7bdgo-5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = []\n",
        "for i in data['subject']:\n",
        "  if i not in s:\n",
        "    s.append(i)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHzKFL0SVzly",
        "outputId": "1c7dd44f-5983-489c-aadc-659e1cef31c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['News', 'politics', 'Government News', 'left-news', 'US_News', 'Middle-east']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5mvjeU3j45Y",
        "outputId": "d7b16773-70fa-4b91-8b34-0e2c216ed5f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = []\n",
        "for i in data['text']:\n",
        "  if type(i) not in t:\n",
        "    t.append(type(i))\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfzFPKk3k4Jg",
        "outputId": "9a62aca1-8979-46d1-c1b2-2ff9821a56f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[str]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = data['title'].tolist()"
      ],
      "metadata": {
        "id": "gkDqUTAVtilE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['text'].tolist()"
      ],
      "metadata": {
        "id": "NmVXvQA8u0yE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ttexts = []\n",
        "for text in texts:\n",
        "  ttexts.append(word_tokenize(text))"
      ],
      "metadata": {
        "id": "a_njcLYbu7-U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max=0\n",
        "for i in ttexts:\n",
        "  if len(i) > max:\n",
        "    max=len(i)\n",
        "max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfeqEpomvNgb",
        "outputId": "ccb12596-a5fc-4b9c-9640-7fc00085c95d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9939"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts = []\n",
        "for i in ttexts:\n",
        "  a = []\n",
        "  for j in i:\n",
        "    a.append(j.lower())\n",
        "  ts.append(a)\n",
        "\n"
      ],
      "metadata": {
        "id": "xuWTShhozvX_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [i[:1000] for i in ts]"
      ],
      "metadata": {
        "id": "wqxSWn320PWm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим новый датафрейм из того что нужно"
      ],
      "metadata": {
        "id": "68F4hWTbpFXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'subj': data['subject'].tolist(), 'texts': pd.Series(texts)})"
      ],
      "metadata": {
        "id": "M9ZuwC0FQ1RK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "y4usZLtoSH_9",
        "outputId": "54970191-d9cb-489b-c3d8-005d069a9b1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74410b25-4cd1-4d0a-90c5-212108ea57e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subj</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>News</td>\n",
              "      <td>[donald, trump, just, couldn, t, wish, all, am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>News</td>\n",
              "      <td>[house, intelligence, committee, chairman, dev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>News</td>\n",
              "      <td>[on, friday, ,, it, was, revealed, that, forme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>News</td>\n",
              "      <td>[on, christmas, day, ,, donald, trump, announc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>News</td>\n",
              "      <td>[pope, francis, used, his, annual, christmas, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23476</th>\n",
              "      <td>Middle-east</td>\n",
              "      <td>[21st, century, wire, says, as, 21wire, report...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23477</th>\n",
              "      <td>Middle-east</td>\n",
              "      <td>[21st, century, wire, says, it, s, a, familiar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23478</th>\n",
              "      <td>Middle-east</td>\n",
              "      <td>[patrick, henningsen, 21st, century, wireremem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23479</th>\n",
              "      <td>Middle-east</td>\n",
              "      <td>[21st, century, wire, says, al, jazeera, ameri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23480</th>\n",
              "      <td>Middle-east</td>\n",
              "      <td>[21st, century, wire, says, as, 21wire, predic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23481 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74410b25-4cd1-4d0a-90c5-212108ea57e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74410b25-4cd1-4d0a-90c5-212108ea57e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74410b25-4cd1-4d0a-90c5-212108ea57e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              subj                                              texts\n",
              "0             News  [donald, trump, just, couldn, t, wish, all, am...\n",
              "1             News  [house, intelligence, committee, chairman, dev...\n",
              "2             News  [on, friday, ,, it, was, revealed, that, forme...\n",
              "3             News  [on, christmas, day, ,, donald, trump, announc...\n",
              "4             News  [pope, francis, used, his, annual, christmas, ...\n",
              "...            ...                                                ...\n",
              "23476  Middle-east  [21st, century, wire, says, as, 21wire, report...\n",
              "23477  Middle-east  [21st, century, wire, says, it, s, a, familiar...\n",
              "23478  Middle-east  [patrick, henningsen, 21st, century, wireremem...\n",
              "23479  Middle-east  [21st, century, wire, says, al, jazeera, ameri...\n",
              "23480  Middle-east  [21st, century, wire, says, as, 21wire, predic...\n",
              "\n",
              "[23481 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(df.subj.unique())}"
      ],
      "metadata": {
        "id": "e58JfiawXKaC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.subj= df.subj.map(cat_mapper)"
      ],
      "metadata": {
        "id": "MM5qv5tLXM1j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим словари для датасета"
      ],
      "metadata": {
        "id": "rCwvPMkKpL-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        vocab[token] += 1"
      ],
      "metadata": {
        "id": "htv3A1YhM0Ph"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = set()\n",
        "for key, value in vocab.items():\n",
        "    if value > 10:\n",
        "        tokens.add(key)"
      ],
      "metadata": {
        "id": "SNgEPTeiNeVm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'PAD':0}\n",
        "\n",
        "for word in tokens:\n",
        "    word2id[word] = len(word2id)"
      ],
      "metadata": {
        "id": "ev0JIvaJN43d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "pz6c-ProN8rB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z38lnMi9XiFQ",
        "outputId": "292228b7-6ff7-4775-9679-c16d196d08b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 332 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipdb"
      ],
      "metadata": {
        "id": "sEBnLgDIX0vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486a8655-8651-499e-9413-4fb1aa9c68b9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 791 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 40.9 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.24 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "from torchmetrics import F1\n",
        "from torchmetrics.functional import f1, recall\n",
        "import ipdb"
      ],
      "metadata": {
        "id": "koNsEWjgTqnc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(df, test_size=0.2, random_state=21, shuffle=True)"
      ],
      "metadata": {
        "id": "5kJGlj43Xf3U"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCPJRkOnWx-b",
        "outputId": "28bf04df-b59c-4c7d-81f8-82a23e9f1d0b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 1000"
      ],
      "metadata": {
        "id": "iinafNqbX05J"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем датасет"
      ],
      "metadata": {
        "id": "wf3Iq0t9pR-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, word2id, DEVICE, max_len=max_len):\n",
        "        self.max_len = max_len\n",
        "        self.dataset = dataset['texts'].values\n",
        "        self.word2id = word2id\n",
        "        self.length = dataset.shape[0]\n",
        "        self.target = dataset['subj'].values\n",
        "        self.device = DEVICE\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        words = self.dataset[index]\n",
        "        ids = torch.LongTensor([self.word2id[word] if word in self.word2id else self.word2id['PAD'] for word in words][:self.max_len])\n",
        "        y = [self.target[index]]\n",
        "        return ids, y\n",
        "\n",
        "    def collate_fn(self, batch): \n",
        "        ids, y = list(zip(*batch))\n",
        "        if max([len(i) for i in ids]) < self.max_len:\n",
        "            padded_ids = pad_sequence(ids, batch_first=True)\n",
        "\n",
        "        else:\n",
        "            padded_ids = torch.vstack([F.pad(torch.LongTensor(text_ids), \n",
        "                                            (0, self.max_len-len(text_ids))) for text_ids in ids])\n",
        "       \n",
        "        padded_ids = padded_ids.to(self.device)\n",
        "        y = torch.squeeze(torch.Tensor(y).long()).to(self.device)\n",
        "        return padded_ids, y"
      ],
      "metadata": {
        "id": "6G7DZ66vW334"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(train_data, word2id, DEVICE)\n",
        "train_sampler = RandomSampler(train_dataset) \n",
        "train_iterator = DataLoader(train_dataset, collate_fn=train_dataset.collate_fn,sampler=train_sampler, batch_size=128)"
      ],
      "metadata": {
        "id": "7vYzDo8dX37f"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = NewsDataset(val_data, word2id, DEVICE)\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_iterator = DataLoader(val_dataset, collate_fn=val_dataset.collate_fn, sampler=val_sampler, batch_size=128)"
      ],
      "metadata": {
        "id": "tbRtoCIQX_RU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачаем эмбеддинги"
      ],
      "metadata": {
        "id": "sAXPO8lNpVvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMY41Lib-7E",
        "outputId": "b41a00f4-0b22-48d1-f9ac-2bd693ecd8fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 14:58:30--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.166.160\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.166.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  73.6MB/s    in 24s     \n",
            "\n",
            "2021-12-29 14:58:54 (66.8 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "w = models.KeyedVectors.load_word2vec_format(\n",
        "    'GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "weights = np.zeros((len(word2id), 300))\n",
        "count = 0\n",
        "for word, i in word2id.items():\n",
        "    if word == 'PAD':\n",
        "        continue   \n",
        "    try:\n",
        "        weights[i] = w[word]    \n",
        "    except KeyError:\n",
        "        count += 1\n",
        "        weights[i] = np.random.normal(0,0.1,300)"
      ],
      "metadata": {
        "id": "SXEjwz10ZSLH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем модель"
      ],
      "metadata": {
        "id": "1AMp5E3TpYl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, weights, lstm_size, out_conv):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(weights), freeze=False)\n",
        "        self.bigrams = nn.Conv1d(in_channels=weights.shape[1], out_channels=out_conv, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.LSTM = nn.LSTM(input_size=out_conv, hidden_size=lstm_size,\n",
        "                          num_layers=1, batch_first=True)\n",
        "        \n",
        "        \n",
        "        self.hidden = nn.Linear(in_features=lstm_size, out_features=6)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "    def forward(self, word):\n",
        "        #batch_size x seq_len\n",
        "        embedded = self.embedding(word)\n",
        "        embedded = embedded.transpose(1,2)\n",
        "        #batch_size x n_channels x seq_length\n",
        "        feature_map_bigrams = self.relu(self.bigrams(self.dropout(embedded)))\n",
        "        #batch_size x n_channels x seq_length\n",
        "        \n",
        "        x, _ = self.LSTM(feature_map_bigrams.transpose(1, 2))\n",
        "        h_s, c_s = _[0], _[1]\n",
        "\n",
        "        logits = self.dropout(self.hidden(h_s.transpose(0, 1).squeeze()))\n",
        "        \n",
        "        return logits"
      ],
      "metadata": {
        "id": "CiCoDpk8YBef"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    print(next(model.parameters()))\n",
        "\n",
        "    epoch_loss = 0 \n",
        "    model.train()  \n",
        "    for i, (texts, ys) in enumerate(iterator): \n",
        "        optimizer.zero_grad() \n",
        "        preds = model(texts)  \n",
        "        loss = criterion(preds, ys) \n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        if not (i + 1) % int(len(iterator)/5):\n",
        "            print(f'Train loss: {epoch_loss/i}') \n",
        "    \n",
        "    print(next(model.parameters()))\n",
        "\n",
        "    return model, epoch_loss / len(iterator) "
      ],
      "metadata": {
        "id": "HS-ynp4dYhuw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_metric = 0\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        for i, (texts, ys) in enumerate(iterator):   \n",
        "            preds = model(texts)  # делаем предсказания на тесте\n",
        "            loss = criterion(preds, ys)   # считаем значения функции ошибки для статистики  \n",
        "            epoch_loss += loss.item()\n",
        "            batch_metric = f1(preds, ys, average='micro', num_classes=6)\n",
        "            epoch_metric += batch_metric\n",
        "\n",
        "            if not (i + 1) % int(len(iterator)/5):\n",
        "                print(f'Val loss: {epoch_loss/(i+1)}, Val f1: {epoch_metric/(i+1)}')\n",
        "\n",
        "    return model, epoch_metric / len(iterator), epoch_loss / len(iterator) "
      ],
      "metadata": {
        "id": "WwX_AD9GYuAF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning(n_epochs, model, optimizer, criterion):\n",
        "    for i in range(n_epochs):\n",
        "        print(f'\\nstarting Epoch {i}')\n",
        "        print('Training...')\n",
        "        model, epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
        "        losses.append(epoch_loss)\n",
        "        print('\\nEvaluating on train...')\n",
        "        model, f1_on_train, _ = evaluate(model, train_iterator, criterion)\n",
        "        f1s.append(f1_on_train.cpu())\n",
        "        print('\\nEvaluating on test...')\n",
        "        model, f1_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
        "        losses_eval.append(epoch_loss_on_test)\n",
        "        f1s_eval.append(f1_on_test.cpu())"
      ],
      "metadata": {
        "id": "WKOFmZ4qYztc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "import sys"
      ],
      "metadata": {
        "id": "W53A96npZDr0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del max"
      ],
      "metadata": {
        "id": "GVJCmr-VmaHc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим!"
      ],
      "metadata": {
        "id": "DcmIsJyrpcJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model = CLSTM(weights, lstm_size=150, out_conv=150)\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=0.005, weight_decay=0.001)\n",
        "    criterion = nn.CrossEntropyLoss() # \n",
        "    model = model.to(DEVICE)\n",
        "    criterion = criterion.to(DEVICE)\n",
        "\n",
        "    losses = []\n",
        "    losses_eval = []\n",
        "    f1s = []\n",
        "    f1s_eval = []\n",
        "\n",
        "    learning(5, model, optimizer, criterion)\n",
        "\n",
        "except Exception or KeyboardInterrupt:\n",
        "    traceback.print_exc()\n",
        "    del model, optimizer, criterion\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUGAv6UvY2un",
        "outputId": "9b4b64ae-df03-4328-c25c-4d6748289118"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "starting Epoch 0\n",
            "Training...\n",
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0352,  0.3535,  0.0664,  ..., -0.2197,  0.0938, -0.0181],\n",
            "        [-0.1226, -0.1777,  0.2354,  ..., -0.2598, -0.2002, -0.0035],\n",
            "        ...,\n",
            "        [-0.1660,  0.0752,  0.0669,  ...,  0.0649, -0.1543,  0.1416],\n",
            "        [ 0.0393, -0.2773, -0.0186,  ..., -0.4180,  0.1963, -0.2295],\n",
            "        [ 0.1348,  0.2598, -0.1338,  ..., -0.1699, -0.4629, -0.0884]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Train loss: 2.263509294816426\n",
            "Train loss: 1.9346798888423986\n",
            "Train loss: 1.8241142159284547\n",
            "Train loss: 1.7690324866253397\n",
            "Train loss: 1.7338049469722643\n",
            "Parameter containing:\n",
            "tensor([[ 1.6306e-01,  4.4648e-02,  1.8040e-01,  ..., -4.6740e-02,\n",
            "          5.5256e-02, -1.6463e-01],\n",
            "        [ 5.7199e-15,  5.6929e-07, -1.5970e-22,  ..., -4.7687e-15,\n",
            "          2.7886e-43,  2.6014e-15],\n",
            "        [-6.8804e-43, -1.1370e-21,  2.0528e-13,  ..., -2.1273e-11,\n",
            "         -1.2624e-17, -8.8097e-37],\n",
            "        ...,\n",
            "        [-1.8331e-24,  1.2612e-44,  6.6281e-43,  ...,  5.7127e-39,\n",
            "         -6.1136e-28,  8.3451e-33],\n",
            "        [-1.8809e-24, -3.0209e-10,  9.7027e-15,  ..., -2.1438e-05,\n",
            "          3.1230e-18, -5.4528e-14],\n",
            "        [-1.1918e-25,  2.1273e-11, -1.1352e-34,  ...,  4.2074e-21,\n",
            "         -1.2350e-04, -6.4600e-43]], device='cuda:0', requires_grad=True)\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 1.4850065543733795, Val f1: 0.3976293206214905\n",
            "Val loss: 1.483043660377634, Val f1: 0.39722520112991333\n",
            "Val loss: 1.484063173162526, Val f1: 0.3987967073917389\n",
            "Val loss: 1.488058762303714, Val f1: 0.39399245381355286\n",
            "Val loss: 1.4858940214946352, Val f1: 0.3949892222881317\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 1.5086811099733626, Val f1: 0.3984375298023224\n",
            "Val loss: 1.4909869943346297, Val f1: 0.412388414144516\n",
            "Val loss: 1.4922103541237968, Val f1: 0.3939732313156128\n",
            "Val loss: 1.4934156622205461, Val f1: 0.3964844048023224\n",
            "Val loss: 1.4937874623707363, Val f1: 0.39866071939468384\n",
            "\n",
            "starting Epoch 1\n",
            "Training...\n",
            "Parameter containing:\n",
            "tensor([[ 1.6306e-01,  4.4648e-02,  1.8040e-01,  ..., -4.6740e-02,\n",
            "          5.5256e-02, -1.6463e-01],\n",
            "        [ 5.7199e-15,  5.6929e-07, -1.5970e-22,  ..., -4.7687e-15,\n",
            "          2.7886e-43,  2.6014e-15],\n",
            "        [-6.8804e-43, -1.1370e-21,  2.0528e-13,  ..., -2.1273e-11,\n",
            "         -1.2624e-17, -8.8097e-37],\n",
            "        ...,\n",
            "        [-1.8331e-24,  1.2612e-44,  6.6281e-43,  ...,  5.7127e-39,\n",
            "         -6.1136e-28,  8.3451e-33],\n",
            "        [-1.8809e-24, -3.0209e-10,  9.7027e-15,  ..., -2.1438e-05,\n",
            "          3.1230e-18, -5.4528e-14],\n",
            "        [-1.1918e-25,  2.1273e-11, -1.1352e-34,  ...,  4.2074e-21,\n",
            "         -1.2350e-04, -6.4600e-43]], device='cuda:0', requires_grad=True)\n",
            "Train loss: 1.6439250111579895\n",
            "Train loss: 1.6203523330521166\n",
            "Train loss: 1.611263140689495\n",
            "Train loss: 1.6079299978587938\n",
            "Train loss: 1.6066719657844968\n",
            "Parameter containing:\n",
            "tensor([[ 1.6998e-01,  3.6036e-02,  1.9028e-01,  ..., -3.9180e-02,\n",
            "          4.3458e-02, -1.6476e-01],\n",
            "        [-6.8611e-05,  2.0231e-19,  1.0610e-13,  ..., -1.8396e-32,\n",
            "         -9.4901e-29, -3.4368e-05],\n",
            "        [ 1.1224e-42, -2.1221e-39, -1.2518e-33,  ...,  1.3502e-21,\n",
            "         -1.4245e-31,  5.4343e-10],\n",
            "        ...,\n",
            "        [-9.1343e-38, -1.0519e-02,  1.3683e-22,  ..., -1.5509e-21,\n",
            "          2.6344e-43, -6.0536e-43],\n",
            "        [ 1.5850e-10, -1.9084e-30, -1.0614e-04,  ..., -2.3328e-14,\n",
            "         -6.7571e-32, -6.3361e-25],\n",
            "        [ 6.4303e-14, -2.5356e-12, -5.7033e-43,  ...,  1.5177e-15,\n",
            "         -5.6620e-12,  1.2755e-15]], device='cuda:0', requires_grad=True)\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 1.5038770560560555, Val f1: 0.37742456793785095\n",
            "Val loss: 1.509300421024191, Val f1: 0.3826777935028076\n",
            "Val loss: 1.5034344114106277, Val f1: 0.3913433849811554\n",
            "Val loss: 1.5022110867089238, Val f1: 0.3938577473163605\n",
            "Val loss: 1.5028912560693148, Val f1: 0.3955819010734558\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 1.522815227508545, Val f1: 0.3984375298023224\n",
            "Val loss: 1.5054512023925781, Val f1: 0.412388414144516\n",
            "Val loss: 1.509238260132926, Val f1: 0.3939732313156128\n",
            "Val loss: 1.510603564126151, Val f1: 0.3964844048023224\n",
            "Val loss: 1.5107411861419677, Val f1: 0.39866071939468384\n",
            "\n",
            "starting Epoch 2\n",
            "Training...\n",
            "Parameter containing:\n",
            "tensor([[ 1.6998e-01,  3.6036e-02,  1.9028e-01,  ..., -3.9180e-02,\n",
            "          4.3458e-02, -1.6476e-01],\n",
            "        [-6.8611e-05,  2.0231e-19,  1.0610e-13,  ..., -1.8396e-32,\n",
            "         -9.4901e-29, -3.4368e-05],\n",
            "        [ 1.1224e-42, -2.1221e-39, -1.2518e-33,  ...,  1.3502e-21,\n",
            "         -1.4245e-31,  5.4343e-10],\n",
            "        ...,\n",
            "        [-9.1343e-38, -1.0519e-02,  1.3683e-22,  ..., -1.5509e-21,\n",
            "          2.6344e-43, -6.0536e-43],\n",
            "        [ 1.5850e-10, -1.9084e-30, -1.0614e-04,  ..., -2.3328e-14,\n",
            "         -6.7571e-32, -6.3361e-25],\n",
            "        [ 6.4303e-14, -2.5356e-12, -5.7033e-43,  ...,  1.5177e-15,\n",
            "         -5.6620e-12,  1.2755e-15]], device='cuda:0', requires_grad=True)\n",
            "Train loss: 1.6580567147050584\n",
            "Train loss: 1.6232594105235316\n",
            "Train loss: 1.613913286563962\n",
            "Train loss: 1.609240935159766\n",
            "Train loss: 1.6045257672667503\n",
            "Parameter containing:\n",
            "tensor([[ 1.6026e-01,  2.1055e-02,  1.8085e-01,  ..., -2.5157e-02,\n",
            "          2.6941e-02, -1.5254e-01],\n",
            "        [ 1.3899e-04,  7.9874e-44, -1.0060e-04,  ..., -1.3733e-43,\n",
            "          1.2212e-09,  1.0811e-04],\n",
            "        [ 1.0639e-23, -5.1837e-39, -2.6625e-44,  ..., -4.4001e-43,\n",
            "         -3.1165e-42, -2.4870e-05],\n",
            "        ...,\n",
            "        [ 3.2370e-43,  7.5199e-04,  1.2477e-02,  ...,  5.9019e-03,\n",
            "          4.0357e-43,  1.4712e-37],\n",
            "        [-3.2974e-03, -4.8485e-43,  1.7018e-04,  ...,  2.5735e-16,\n",
            "          1.6844e-25,  6.1517e-43],\n",
            "        [ 2.4380e-28, -3.5238e-22,  1.8307e-07,  ...,  1.8395e-12,\n",
            "         -2.3513e-13, -1.5170e-06]], device='cuda:0', requires_grad=True)\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 1.4831911078814803, Val f1: 0.4040948152542114\n",
            "Val loss: 1.487564606913205, Val f1: 0.3966864347457886\n",
            "Val loss: 1.485566462593517, Val f1: 0.3998742699623108\n",
            "Val loss: 1.4868143139214351, Val f1: 0.39978447556495667\n",
            "Val loss: 1.4889311469834425, Val f1: 0.3956896662712097\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 1.5071932247706823, Val f1: 0.3984375298023224\n",
            "Val loss: 1.4895170841898238, Val f1: 0.412388414144516\n",
            "Val loss: 1.4954566558202107, Val f1: 0.3943452537059784\n",
            "Val loss: 1.4959822935717446, Val f1: 0.396763414144516\n",
            "Val loss: 1.4959810052599225, Val f1: 0.3988839387893677\n",
            "\n",
            "starting Epoch 3\n",
            "Training...\n",
            "Parameter containing:\n",
            "tensor([[ 1.6026e-01,  2.1055e-02,  1.8085e-01,  ..., -2.5157e-02,\n",
            "          2.6941e-02, -1.5254e-01],\n",
            "        [ 1.3899e-04,  7.9874e-44, -1.0060e-04,  ..., -1.3733e-43,\n",
            "          1.2212e-09,  1.0811e-04],\n",
            "        [ 1.0639e-23, -5.1837e-39, -2.6625e-44,  ..., -4.4001e-43,\n",
            "         -3.1165e-42, -2.4870e-05],\n",
            "        ...,\n",
            "        [ 3.2370e-43,  7.5199e-04,  1.2477e-02,  ...,  5.9019e-03,\n",
            "          4.0357e-43,  1.4712e-37],\n",
            "        [-3.2974e-03, -4.8485e-43,  1.7018e-04,  ...,  2.5735e-16,\n",
            "          1.6844e-25,  6.1517e-43],\n",
            "        [ 2.4380e-28, -3.5238e-22,  1.8307e-07,  ...,  1.8395e-12,\n",
            "         -2.3513e-13, -1.5170e-06]], device='cuda:0', requires_grad=True)\n",
            "Train loss: 1.6580085924693517\n",
            "Train loss: 1.6272964184744316\n",
            "Train loss: 1.6124771001727083\n",
            "Train loss: 1.607345382027004\n",
            "Train loss: 1.6036750715639856\n",
            "Parameter containing:\n",
            "tensor([[ 1.2218e-01,  5.3759e-03,  1.6199e-01,  ..., -7.9119e-03,\n",
            "          4.2459e-03, -1.2632e-01],\n",
            "        [-1.2762e-03, -1.3448e-39,  4.7360e-05,  ..., -8.5651e-29,\n",
            "         -4.5975e-05, -1.5439e-03],\n",
            "        [-2.0491e-10,  5.3562e-08, -3.7415e-43,  ..., -1.6549e-42,\n",
            "          2.0784e-24,  5.5500e-03],\n",
            "        ...,\n",
            "        [-3.0593e-07, -7.4835e-04, -4.4941e-04,  ..., -1.5831e-04,\n",
            "         -5.2321e-03, -1.6345e-10],\n",
            "        [ 5.3866e-04,  2.5321e-40, -1.1272e-03,  ...,  1.3915e-41,\n",
            "         -5.0634e-26,  2.3592e-07],\n",
            "        [ 1.1006e-02,  6.9504e-43, -2.3221e-05,  ...,  1.2730e-06,\n",
            "         -1.1070e-43,  1.1790e-04]], device='cuda:0', requires_grad=True)\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 1.4929373346526047, Val f1: 0.28394395112991333\n",
            "Val loss: 1.494221080993784, Val f1: 0.2900053858757019\n",
            "Val loss: 1.4965300217442128, Val f1: 0.28816449642181396\n",
            "Val loss: 1.4942971950974957, Val f1: 0.2922952473163605\n",
            "Val loss: 1.4943713607459232, Val f1: 0.2931034564971924\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 1.5192492008209229, Val f1: 0.2667410969734192\n",
            "Val loss: 1.5027648551123483, Val f1: 0.2684151828289032\n",
            "Val loss: 1.5014486937295823, Val f1: 0.2879464328289032\n",
            "Val loss: 1.503597923687526, Val f1: 0.2837611734867096\n",
            "Val loss: 1.5036431925637381, Val f1: 0.2828125059604645\n",
            "\n",
            "starting Epoch 4\n",
            "Training...\n",
            "Parameter containing:\n",
            "tensor([[ 1.2218e-01,  5.3759e-03,  1.6199e-01,  ..., -7.9119e-03,\n",
            "          4.2459e-03, -1.2632e-01],\n",
            "        [-1.2762e-03, -1.3448e-39,  4.7360e-05,  ..., -8.5651e-29,\n",
            "         -4.5975e-05, -1.5439e-03],\n",
            "        [-2.0491e-10,  5.3562e-08, -3.7415e-43,  ..., -1.6549e-42,\n",
            "          2.0784e-24,  5.5500e-03],\n",
            "        ...,\n",
            "        [-3.0593e-07, -7.4835e-04, -4.4941e-04,  ..., -1.5831e-04,\n",
            "         -5.2321e-03, -1.6345e-10],\n",
            "        [ 5.3866e-04,  2.5321e-40, -1.1272e-03,  ...,  1.3915e-41,\n",
            "         -5.0634e-26,  2.3592e-07],\n",
            "        [ 1.1006e-02,  6.9504e-43, -2.3221e-05,  ...,  1.2730e-06,\n",
            "         -1.1070e-43,  1.1790e-04]], device='cuda:0', requires_grad=True)\n",
            "Train loss: 1.6550414860248566\n",
            "Train loss: 1.6217685080411142\n",
            "Train loss: 1.6116232317547465\n",
            "Train loss: 1.6083031550697657\n",
            "Train loss: 1.6065171617600653\n",
            "Parameter containing:\n",
            "tensor([[ 6.5965e-02,  2.6076e-04,  1.3028e-01,  ..., -1.3338e-04,\n",
            "          6.2952e-05, -6.6381e-02],\n",
            "        [ 1.7107e-03, -1.5663e-27, -3.8165e-03,  ...,  3.8905e-11,\n",
            "          5.7325e-03,  1.8591e-03],\n",
            "        [ 6.9474e-04, -2.4408e-03, -3.7415e-43,  ...,  2.2436e-14,\n",
            "         -1.2333e-10, -3.4623e-03],\n",
            "        ...,\n",
            "        [ 1.3501e-02,  1.5004e-03,  8.1953e-04,  ...,  1.2801e-03,\n",
            "          1.3360e-03,  2.6987e-07],\n",
            "        [-1.8791e-03,  9.7705e-17,  1.6270e-03,  ...,  2.8306e-43,\n",
            "          2.3688e-11, -6.4222e-05],\n",
            "        [-6.8969e-03,  1.4656e-08,  7.2170e-04,  ..., -2.2693e-04,\n",
            "         -4.9045e-43, -1.4631e-03]], device='cuda:0', requires_grad=True)\n",
            "\n",
            "Evaluating on train...\n",
            "Val loss: 1.477314122791948, Val f1: 0.4030172526836395\n",
            "Val loss: 1.4799720398310958, Val f1: 0.3966864347457886\n",
            "Val loss: 1.4781639904811466, Val f1: 0.39744970202445984\n",
            "Val loss: 1.4778325136365562, Val f1: 0.3956088423728943\n",
            "Val loss: 1.4797266220224314, Val f1: 0.3956896662712097\n",
            "\n",
            "Evaluating on test...\n",
            "Val loss: 1.4984910658427648, Val f1: 0.3984375298023224\n",
            "Val loss: 1.4791830011776514, Val f1: 0.412388414144516\n",
            "Val loss: 1.4857825211116247, Val f1: 0.3939732313156128\n",
            "Val loss: 1.4863570502826147, Val f1: 0.3964844048023224\n",
            "Val loss: 1.4860180105481828, Val f1: 0.39866071939468384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "FEKkdoqCyD_G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.plot(losses_eval)\n",
        "plt.title('BCE loss value')\n",
        "plt.ylabel('BCE loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "x535N1_Wx9-H",
        "outputId": "870c55ef-4aa0-4275-a494-2772ee30430b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ну, модель не обучается... жалко((("
      ],
      "metadata": {
        "id": "rPR379GtDe-R"
      }
    }
  ]
}